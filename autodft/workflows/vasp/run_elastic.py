import os
import subprocess
import shutil
import re

import time


incar_params = {
    # Precision and convergence settings
    "# Precision and convergence settings": '',
    "PREC": "High",
    "NELMIN": 8,
    "NELM": 100,
    "EDIFF": 1e-08,
    "EDIFFG": -1e-04,
    '# End Precision and convergence settings': '\n',
    
    # Electronic structure settings
    "# Electronic structure settings": '',
    "ISMEAR": 1,
    "SIGMA": 0.05,
    "ISPIN": 2,
    "ICHARG": 1,
    "NEDOS": 300,
    '# End Electronic structure settings': '\n',
    
    # Optimization settings
    "# Optimization settings": '',
    "LREAL": False,
    "IBRION": 6,
    "NSW": 1,
    "ISIF": 3,
    "POTIM":0.015,
    "NFREE": 2,
    "ENCUT": 600,
    '# End Optimization settings': '\n',

    # Wavefunction and grid settings
    "# Wavefunction and grid settings": '',
    "LWAVE": False,
    "LASPH": True,
    "LORBIT": 11,
    "LMAXMIX": 4,
    "ADDGRID": True,
    "NWRITE": 3,
    '# End Wavefunction and grid settings': '\n',
    
    
    
    # Parallelization parameters
    "# Parallelization parameters": '',
    "KPAR": 10,
    "NPAR": 6,
    '# End Parallelization parameters': '\n'
}

MASTER_SLURM_STRING = """#!/bin/bash
#SBATCH -J Ti_elastic-master
#SBATCH --nodes=1
#SBATCH -n 1
#SBATCH -p comm_small_day
#SBATCH -t 24:00:00

export NUM_CORES=$((SLURM_JOB_NUM_NODES * SLURM_CPUS_ON_NODE))
echo "Number of cores $NUM_CORES cores."
source ~/.bashrc

source /shared/software/conda/conda_init.sh

module load atomistic/vasp/6.2.1_intel22_impi22

# Start of submission executions of subdirectories

"""



def check_if_previous_convergence(dir, ediff, ediffg, convergence_method = None):
    oszicar=os.path.join(dir,'OSZICAR')

    if os.path.exists(oszicar):
        "aborting loop because EDIFF is reached"
        
        with open(oszicar) as f:
            lines = f.readlines()
            for line in lines:
                if "DAV" in line:
                    raw_values = line.split()
                    de = float(raw_values[2])
                    rms = float(raw_values[-2])
                    
                    
        if de < ediff and rms < ediffg:
            return True
        else:
            return False
    else:
        return False
    
    
    
def wait_for_job_completion(job_id, check_interval=30):
    """
    Wait for a SLURM job to complete by monitoring the job queue.
    
    Args:
        job_id (int): The SLURM job ID.
        check_interval (int): Time interval (in seconds) between status checks.
    """
    while True:
        # Check the job status using squeue
        result = subprocess.run(["squeue", "-j", str(job_id)], capture_output=True, text=True)
        if result.returncode != 0:
            raise RuntimeError(f"Failed to check SLURM queue: {result.stderr.strip()}")
        
        # If the job ID is not in the queue, it has completed
        if str(job_id) not in result.stdout:
            print(f"Job {job_id} has completed.")
            break
        
        print(f"Job {job_id} is still running. Checking again in {check_interval} seconds...")
        time.sleep(check_interval)


def setup_elastic(root_dir, out_dir, kpoints_params):
    

    root_dir = os.path.dirname(os.path.abspath(__file__))
    scf_dir = os.path.join(root_dir, "scf")
    
    is_converged = check_if_previous_convergence(scf_dir, 
                                             ediff=incar_params["EDIFF"], 
                                             ediffg=incar_params["EDIFFG"])

    if is_converged:
        print("Previous calculation converged. No need to run.")
        return None
    
    print("Previous calculation did not converge or did not exist. Running new calculation.")
    os.makedirs(out_dir, exist_ok=True)
    
    
    if os.path.exists(os.path.join(scf_dir,'CHGCAR')):
        shutil.copyfile(os.path.join(scf_dir,'CHGCAR'), os.path.join(out_dir,'CHGCAR'))
    else:
        raise FileNotFoundError("Self-consistent calculation not found. Please run run_scf.py first.")

    
    with open(os.path.join(root_dir, "POSCAR"), "r") as f:
        lines=f.readlines()
        system_name=lines[0].replace('\n','').strip()
    
    with open(os.path.join(out_dir, "INCAR"), "w") as f:
        
        f.write(f"system   =  {system_name}\n")
        for key, value in incar_params.items():
            f.write(f"{key} = {value}\n")
        f.write("\n")
        
    with open(os.path.join(out_dir, "KPOINTS"), "w") as f:
        f.write(f"KPOINTS generated by run_elastic.py\n")
        f.write(f"0\n")
        f.write(f"{kpoints_params['type']}\n")
        f.write(f"{' '.join(map(str, kpoints_params['grid']))}\n")
        f.write(f"{' '.join(map(str, kpoints_params['shift']))}\n")
        
    
        
    with open(os.path.join(root_dir, "run.slurm"), "r") as f:
        submission_lines=f.readlines()
        submission_lines[1] = f"#SBATCH -J {system_name}_elastic-kpoint{kpoints_params['grid'][0]}\n"
        
    with open(os.path.join(out_dir, "run.slurm"), "w") as f:
        f.writelines(submission_lines)
        
        
    shutil.copyfile(os.path.join(root_dir,'POTCAR'), os.path.join(out_dir,'POTCAR'))
    shutil.copyfile(os.path.join(root_dir,'POSCAR'), os.path.join(out_dir,'POSCAR'))

    os.chdir(f'{out_dir}')
    result = subprocess.run(['sbatch', f'run.slurm'], capture_output=False, text=True)
    
    # # Check if submission was successful
    # if result.returncode != 0:
    #     raise RuntimeError(f"Failed to submit SLURM script: {result.stderr.strip()}")
    
    
    # # Extract the job ID from the output
    # output = result.stdout.strip()
    # print(f"SLURM submission output: {output}")
    # job_id = int(output.split()[-1])  # Job ID is typically the last word in sbatch output


def main():
    
    root_dir = os.path.dirname(os.path.abspath(__file__))
    elastic_dir = os.path.join(root_dir, "elastic")
    
    
    outcar = os.path.join(elastic_dir, "OUTCAR")
    
    if os.path.exists(outcar):
        print("Previous master elastic calculation converged. No need to run.")
        return None
    
    os.makedirs(elastic_dir, exist_ok=True)
    
    print("Previous master elastic calculation did not converge or did not exist. Running new calculation.")
    
    master_slurm_string = MASTER_SLURM_STRING
    for x in range(7,18,2):
        kpoints_params = {
            'type': 'gamma',
            'grid': (x, x, x),
            'shift': (0, 0, 0),
        }
        out_dir = os.path.join(elastic_dir, f"KPOINTS-{x}")
        setup_elastic(root_dir, out_dir, kpoints_params)
        
        # master_slurm_string += f"cd {out_dir}\n"
        # master_slurm_string += f"sbatch run.slurm\n\n"
        
    
    # with open(os.path.join(root_dir, "POSCAR"), "r") as f:
    #     lines=f.readlines()
    #     system_name=lines[0].replace('\n','')
        
    # submission_lines = master_slurm_string.splitlines()
    # submission_lines[1] = f"#SBATCH -J {system_name}_elastic-master"
    
    # print(submission_lines)
        
    # with open(os.path.join(elastic_dir, "run.slurm"), "w") as f:
    #     for line in submission_lines:
    #         f.write("\n")
    #         f.write(line)
            

        
    # os.chdir(f'{elastic_dir}')
    # result = subprocess.run(['sbatch', f'run.slurm'], capture_output=False, text=True)
        
    # result = subprocess.run(['sbatch', f'run.slurm'], capture_output=True, text=True)
    
    # # Check if submission was successful
    # if result.returncode != 0:
    #     raise RuntimeError(f"Failed to submit SLURM script: {result.stderr.strip()}")
    
    
    # # Extract the job ID from the output
    # output = result.stdout.strip()
    # print(f"SLURM submission output: {output}")
    # job_id = int(output.split()[-1])  # Job ID is typically the last word in sbatch output
    
    
    # wait_for_job_completion(job_id, check_interval=30)
        
    

if __name__ == "__main__":
    main()






